#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
inference.py
------------
EÄŸitilmiÅŸ model ile tahmin yapma (inference) scripti.
Yeni MRI gÃ¶rÃ¼ntÃ¼leri iÃ§in demans seviyesi tahmini yapar.

KullanÄ±m:
    python3 inference.py --model path/to/model.pkl --image path/to/image.jpg
    python3 inference.py --model xgboost_latest.pkl --batch path/to/images/
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent))

import argparse
import pickle
import json
import numpy as np
import pandas as pd
from typing import Union, List, Dict, Optional
from multiprocessing import Pool, cpu_count
from functools import partial
from tqdm import tqdm

# GÃ¶rÃ¼ntÃ¼ iÅŸleme iÃ§in
sys.path.insert(0, str(Path(__file__).parent.parent / "goruntu_isleme"))
from goruntu_isleyici import GorselIsleyici
from ozellik_cikarici import OzellikCikarici

from ayarlar import MODELS_KLASORU


def _batch_tahmin_wrapper(goruntu_yolu: Path, model_yolu: Path) -> Dict:
    """âš¡ Paralel batch tahmin iÃ§in wrapper fonksiyon."""
    try:
        inference = ModelInference(model_yolu)
        return inference.tahmin_yap(goruntu_yolu, detayli=False)
    except Exception as e:
        return {
            'dosya': str(goruntu_yolu),
            'hata': str(e)
        }


class ModelInference:
    """EÄŸitilmiÅŸ model ile tahmin yapma sÄ±nÄ±fÄ±."""
    
    def __init__(self, model_yolu: Union[str, Path]):
        """
        Inference nesnesini baÅŸlat.
        
        Args:
            model_yolu: EÄŸitilmiÅŸ model dosyasÄ±nÄ±n yolu (.pkl)
        """
        self.model_yolu = Path(model_yolu)
        
        if not self.model_yolu.exists():
            # MODELS_KLASORU iÃ§inde ara
            alternatif = MODELS_KLASORU / self.model_yolu.name
            if alternatif.exists():
                self.model_yolu = alternatif
            else:
                raise FileNotFoundError(f"Model bulunamadÄ±: {model_yolu}")
        
        # Modeli yÃ¼kle
        self._model_yukle()
        
        # GÃ¶rÃ¼ntÃ¼ iÅŸleyicileri
        self.isleyici = GorselIsleyici()
        self.cikarici = OzellikCikarici()
        
        # SÄ±nÄ±f isimleri
        self.sinif_isimleri = {
            0: "NonDemented (SaÄŸlÄ±klÄ±)",
            1: "VeryMildDemented (Ã‡ok Hafif Demans)",
            2: "MildDemented (Hafif Demans)",
            3: "ModerateDemented (Orta Seviye Demans)"
        }
        
        # âš¡ Paralel iÅŸlem iÃ§in
        self.n_jobs = max(1, cpu_count() - 1)
    
    def _model_yukle(self):
        """Modeli ve metadata'sÄ±nÄ± yÃ¼kle."""
        print(f"\nğŸ“¦ Model yÃ¼kleniyor: {self.model_yolu.name}")
        
        # Pickle model yÃ¼kle
        with open(self.model_yolu, 'rb') as f:
            self.model = pickle.load(f)
        print(f"   âœ“ Model yÃ¼klendi")
        
        # Metadata yÃ¼kle (varsa)
        metadata_yolu = self.model_yolu.with_suffix('.json')
        if metadata_yolu.exists():
            with open(metadata_yolu, 'r', encoding='utf-8') as f:
                self.metadata = json.load(f)
            print(f"   âœ“ Metadata yÃ¼klendi")
            print(f"   â„¹ï¸  Model Tipi: {self.metadata.get('model_tipi', 'N/A')}")
            print(f"   â„¹ï¸  EÄŸitim Tarihi: {self.metadata.get('tarih', 'N/A')}")
            
            # Metrikler varsa gÃ¶ster
            if 'metrikler' in self.metadata:
                metriks = self.metadata['metrikler']
                print(f"   â„¹ï¸  Test Accuracy: {metriks.get('accuracy', 'N/A'):.4f}")
        else:
            self.metadata = {}
            print(f"   âš ï¸  Metadata bulunamadÄ±")
    
    def goruntu_isle(self, goruntu_yolu: Union[str, Path]) -> np.ndarray:
        """
        GÃ¶rÃ¼ntÃ¼yÃ¼ iÅŸle ve model iÃ§in hazÄ±rla.
        
        Args:
            goruntu_yolu: Ham gÃ¶rÃ¼ntÃ¼ dosyasÄ±nÄ±n yolu
            
        Returns:
            Ä°ÅŸlenmiÅŸ gÃ¶rÃ¼ntÃ¼
        """
        goruntu = self.isleyici.goruntu_yukle(str(goruntu_yolu))
        if goruntu is None:
            raise ValueError(f"GÃ¶rÃ¼ntÃ¼ yÃ¼klenemedi: {goruntu_yolu}")
        
        # Tam iÅŸleme pipeline'Ä±
        goruntu = self.isleyici.gurultu_gider(goruntu)
        goruntu = self.isleyici.bias_field_correction(goruntu)
        goruntu = self.isleyici.skull_strip(goruntu)
        goruntu = self.isleyici.center_of_mass_alignment(goruntu)
        goruntu = self.isleyici.yogunluk_normalize(goruntu)
        goruntu = self.isleyici.histogram_esitle(goruntu, adaptive=True)
        goruntu = self.isleyici.boyutlandir(goruntu)
        
        return goruntu
    
    def ozellik_cikar(self, goruntu_yolu: Union[str, Path]) -> pd.DataFrame:
        """
        GÃ¶rÃ¼ntÃ¼den Ã¶zellikleri Ã§Ä±kar.
        
        Args:
            goruntu_yolu: GÃ¶rÃ¼ntÃ¼ dosyasÄ±nÄ±n yolu
            
        Returns:
            Ã–zellikler DataFrame'i
        """
        ozellikler = self.cikarici.tek_goruntu_ozellikleri(str(goruntu_yolu))
        
        if ozellikler is None:
            raise ValueError(f"Ã–zellik Ã§Ä±karÄ±lamadÄ±: {goruntu_yolu}")
        
        # DataFrame'e Ã§evir
        df = pd.DataFrame([ozellikler])
        
        # Kategorik kolonlarÄ± Ã§Ä±kar
        kategorik = ['dosya_adi', 'tam_yol']
        df_ozellikler = df.drop(columns=[c for c in kategorik if c in df.columns])
        
        return df_ozellikler
    
    def tahmin_yap(self, goruntu_yolu: Union[str, Path], 
                   detayli: bool = True) -> Dict:
        """
        Tek bir gÃ¶rÃ¼ntÃ¼ iÃ§in demans seviyesi tahmini yap.
        
        Bu fonksiyon, ham MRI gÃ¶rÃ¼ntÃ¼sÃ¼nÃ¼ alÄ±r ve ÅŸu adÄ±mlarÄ± gerÃ§ekleÅŸtirir:
        1. GÃ¶rÃ¼ntÃ¼yÃ¼ iÅŸle (normalizasyon, yeniden boyutlandÄ±rma, vb.)
        2. Ã–zellikleri Ã§Ä±kar (20+ sayÄ±sal Ã¶zellik)
        3. Model ile tahmin yap
        4. OlasÄ±lÄ±klarÄ± ve gÃ¼ven skorunu hesapla
        
        Ã‡Ä±ktÄ± Ã¶rnekleri:
        {
            'tahmin': 'NonDemented (SaÄŸlÄ±klÄ±)',
            'tahmin_kodu': 0,
            'guven': 0.92,
            'olasiliklar': {
                'NonDemented': 0.92,
                'VeryMildDemented': 0.05,
                'MildDemented': 0.02,
                'ModerateDemented': 0.01
            },
            'goruntu_yolu': '/path/to/image.jpg'
        }
        
        Args:
            goruntu_yolu: MRI gÃ¶rÃ¼ntÃ¼sÃ¼nÃ¼n dosya yolu
            detayli: True ise tÃ¼m olasÄ±lÄ±klarÄ± da dÃ¶ndÃ¼r
            
        Returns:
            Dict: Tahmin sonuÃ§larÄ± (tahmin, gÃ¼ven, olasÄ±lÄ±klar)
        """
        """
        Tek bir gÃ¶rÃ¼ntÃ¼ iÃ§in tahmin yap.
        
        Args:
            goruntu_yolu: GÃ¶rÃ¼ntÃ¼ dosyasÄ±nÄ±n yolu
            detayli: DetaylÄ± Ã§Ä±ktÄ± (olasÄ±lÄ±klar dahil)
            
        Returns:
            Tahmin sonuÃ§larÄ± sÃ¶zlÃ¼ÄŸÃ¼
        """
        print(f"\nğŸ” Tahmin yapÄ±lÄ±yor: {Path(goruntu_yolu).name}")
        
        # Ã–zellikleri Ã§Ä±kar
        X = self.ozellik_cikar(goruntu_yolu)
        
        # Tahmin yap
        tahmin = self.model.predict(X)[0]
        sinif_adi = self.sinif_isimleri[tahmin]
        
        sonuc = {
            'dosya': str(goruntu_yolu),
            'tahmin_sinif': int(tahmin),
            'tahmin_adi': sinif_adi
        }
        
        # OlasÄ±lÄ±klar (varsa)
        if hasattr(self.model, 'predict_proba'):
            olasiliklar = self.model.predict_proba(X)[0]
            sonuc['olasiliklar'] = {
                self.sinif_isimleri[i]: float(prob) 
                for i, prob in enumerate(olasiliklar)
            }
            sonuc['guven_skoru'] = float(max(olasiliklar))
        
        # Ekrana yazdÄ±r
        print(f"\n{'='*60}")
        print(f"ğŸ“Š TAHMÄ°N SONUCU")
        print(f"{'='*60}")
        print(f"ğŸ¯ Tahmin: {sinif_adi}")
        
        if 'guven_skoru' in sonuc:
            print(f"ğŸ“ˆ GÃ¼ven Skoru: {sonuc['guven_skoru']:.2%}")
            
            if detayli:
                print(f"\nğŸ“‹ SÄ±nÄ±f OlasÄ±lÄ±klarÄ±:")
                for sinif, prob in sorted(sonuc['olasiliklar'].items(), 
                                         key=lambda x: x[1], reverse=True):
                    bar = 'â–ˆ' * int(prob * 40)
                    print(f"   {sinif:40s}: {prob:6.2%} {bar}")
        
        print(f"{'='*60}\n")
        
        return sonuc
    
    def batch_tahmin(self, goruntu_klasoru: Union[str, Path], 
                     kaydet: bool = True) -> List[Dict]:
        """
        Bir klasÃ¶rdeki tÃ¼m gÃ¶rÃ¼ntÃ¼ler iÃ§in toplu tahmin yap.
        
        Bu fonksiyon, klinik kullanÄ±m iÃ§in idealdir:
        - Ã‡ok sayÄ±da hasta gÃ¶rÃ¼ntÃ¼sÃ¼nÃ¼ tek seferde iÅŸler
        - SonuÃ§larÄ± CSV'ye kaydeder (raporlama iÃ§in)
        - Ä°lerleme Ã§ubuÄŸu gÃ¶sterir
        
        Ã‡Ä±ktÄ± CSV formatÄ±:
        | goruntu_adi | tahmin | tahmin_kodu | guven | NonDemented | VeryMildDemented | ... |
        |-------------|--------|-------------|-------|-------------|------------------|-----|
        | img1.jpg    | NonDemented | 0 | 0.92 | 0.92 | 0.05 | ... |
        
        KullanÄ±m senaryosu:
        ```python
        inferencer = ModelInference('xgboost_model.pkl')
        sonuclar = inferencer.batch_tahmin('./yeni_hastalar/')
        # SonuÃ§lar otomatik CSV'ye kaydedilir
        ```
        
        Args:
            goruntu_klasoru: GÃ¶rÃ¼ntÃ¼lerin bulunduÄŸu klasÃ¶r yolu
            kaydet: SonuÃ§larÄ± CSV'ye kaydet (varsayÄ±lan: True)
            
        Returns:
            List[Dict]: TÃ¼m tahmin sonuÃ§larÄ±
        """
        klasor = Path(goruntu_klasoru)
        
        if not klasor.exists():
            raise FileNotFoundError(f"KlasÃ¶r bulunamadÄ±: {goruntu_klasoru}")
        
        # GÃ¶rÃ¼ntÃ¼leri bul
        gorseller = list(klasor.glob("*.jpg")) + list(klasor.glob("*.png"))
        
        if not gorseller:
            print(f"âš ï¸  KlasÃ¶rde gÃ¶rÃ¼ntÃ¼ bulunamadÄ±: {goruntu_klasoru}")
            return []
        
        print(f"\nâš¡ Batch tahmin: {len(gorseller)} gÃ¶rÃ¼ntÃ¼ (paralel: {self.n_jobs} Ã§ekirdek)")
        print(f"{'='*60}")
        
        # âš¡ Paralel batch tahmin
        partial_func = partial(_batch_tahmin_wrapper, model_yolu=self.model_yolu)
        
        with Pool(processes=self.n_jobs) as pool:
            sonuclar = list(tqdm(
                pool.imap(partial_func, gorseller),
                total=len(gorseller),
                desc="Batch tahmin (paralel)"
            ))
        
        # Ã–zet
        print(f"\n{'='*60}")
        print(f"ğŸ“Š BATCH TAHMÄ°N Ã–ZETÄ°")
        print(f"{'='*60}")
        print(f"Toplam: {len(gorseller)}")
        print(f"BaÅŸarÄ±lÄ±: {len([s for s in sonuclar if 'tahmin_sinif' in s])}")
        print(f"HatalÄ±: {len([s for s in sonuclar if 'hata' in s])}")
        
        # SÄ±nÄ±f daÄŸÄ±lÄ±mÄ±
        if sonuclar:
            sinif_sayilari = {}
            for sonuc in sonuclar:
                if 'tahmin_adi' in sonuc:
                    sinif = sonuc['tahmin_adi']
                    sinif_sayilari[sinif] = sinif_sayilari.get(sinif, 0) + 1
            
            print(f"\nğŸ“ˆ Tahmin DaÄŸÄ±lÄ±mÄ±:")
            for sinif, sayi in sorted(sinif_sayilari.items()):
                print(f"   {sinif:40s}: {sayi:3d}")
        
        # Kaydet
        if kaydet and sonuclar:
            cikti_dosya = klasor / f"tahminler_{Path(self.model_yolu).stem}.csv"
            df = pd.DataFrame(sonuclar)
            df.to_csv(cikti_dosya, index=False, encoding='utf-8')
            print(f"\nğŸ’¾ SonuÃ§lar kaydedildi: {cikti_dosya}")
        
        return sonuclar


def main():
    """Ana fonksiyon."""
    parser = argparse.ArgumentParser(
        description="EÄŸitilmiÅŸ model ile MRI tahmin (inference)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Ã–rnekler:
  # Tek gÃ¶rÃ¼ntÃ¼ tahmin
  python3 inference.py --model xgboost_latest.pkl --image test.jpg
  
  # Batch tahmin (klasÃ¶rdeki tÃ¼m gÃ¶rÃ¼ntÃ¼ler)
  python3 inference.py --model xgboost_latest.pkl --batch ./test_images/
  
  # En son eÄŸitilmiÅŸ model ile tahmin
  python3 inference.py --image test.jpg
        """
    )
    
    parser.add_argument(
        '--model',
        type=str,
        help='Model dosyasÄ± yolu (.pkl). Belirtilmezse en son model kullanÄ±lÄ±r.'
    )
    
    parser.add_argument(
        '--image',
        type=str,
        help='Tahmin yapÄ±lacak tek bir gÃ¶rÃ¼ntÃ¼ dosyasÄ±'
    )
    
    parser.add_argument(
        '--batch',
        type=str,
        help='Tahmin yapÄ±lacak gÃ¶rÃ¼ntÃ¼lerin bulunduÄŸu klasÃ¶r'
    )
    
    parser.add_argument(
        '--no-save',
        action='store_true',
        help='Batch tahmin sonuÃ§larÄ±nÄ± kaydetme'
    )
    
    args = parser.parse_args()
    
    # Parametre kontrolÃ¼
    if not args.image and not args.batch:
        parser.error("--image veya --batch belirtilmeli")
    
    # Model yolu
    if args.model:
        model_yolu = args.model
    else:
        # En son model ara
        modeller = sorted(MODELS_KLASORU.glob("*.pkl"), key=lambda p: p.stat().st_mtime)
        if not modeller:
            print("âŒ HiÃ§ model bulunamadÄ±!")
            print(f"   Aranan klasÃ¶r: {MODELS_KLASORU}")
            print(f"\nğŸ’¡ Ã–nce model eÄŸitin:")
            print(f"   python3 train.py --auto")
            return 1
        
        model_yolu = modeller[-1]
        print(f"â„¹ï¸  En son model kullanÄ±lÄ±yor: {model_yolu.name}")
    
    try:
        # Inference nesnesi oluÅŸtur
        inferencer = ModelInference(model_yolu)
        
        # Tek gÃ¶rÃ¼ntÃ¼ veya batch
        if args.image:
            inferencer.tahmin_yap(args.image, detayli=True)
        elif args.batch:
            inferencer.batch_tahmin(args.batch, kaydet=not args.no_save)
        
        return 0
        
    except Exception as e:
        print(f"\nâŒ HATA: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())
